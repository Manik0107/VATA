from dotenv import load_dotenv
import os
import json
from google import genai
from google.genai import types

load_dotenv()

JSON_METADATA_PATH = "output/linear_regression_notes.json"
MARKDOWN_PATH = "output/linear_regression_notes.md"
IMAGES_FOLDER = "output/linear_regression_notes_images"
PROMPT_FILE_PATH = "prompts/prompt.txt"
OUTPUT_MANIM_FILE = "generated_linear_regression_animation.py"

def load_text(path):
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

def load_and_process_metadata(path):
    """Load and enhance metadata with image information"""
    try:
        with open(path, "r", encoding="utf-8") as f:
            metadata = json.load(f)
        
        # Add image context information to metadata
        if "images" in metadata:
            image_summary = f"Document contains {len(metadata['images'])} images:\n"
            for img in metadata["images"]:
                image_summary += f"- {img['image_name']}: {img['context_type']} (keywords: {', '.join(img['keywords'])})\n"
            metadata["image_summary"] = image_summary
        
        return json.dumps(metadata, indent=2)
    except:
        return "{}"

def list_image_paths(folder):
    allowed = (".png", ".jpg", ".jpeg", ".gif")
    try:
        return [
            os.path.join(folder, fname)
            for fname in os.listdir(folder)
            if fname.lower().endswith(allowed)
        ]
    except:
        return []

def escape_braces(text):
    import re
    placeholders = ["query", "document_content", "metadata", "images"]
    pattern = re.compile(r"\{(\w+)\}")
    
    token_map = {}
    def replace_placeholder(m):
        key = m.group(1)
        if key in placeholders:
            token = f"@@PLACEHOLDER_{key.upper()}@@"
            token_map[token] = m.group(0)
            return token
        else:
            return m.group(0)

    text_with_tokens = pattern.sub(replace_placeholder, text)
    text_escaped = text_with_tokens.replace("{", "{{").replace("}", "}}")
    
    for token, placeholder in token_map.items():
        text_escaped = text_escaped.replace(token, placeholder)
    
    return text_escaped

def validate_generated_code(code):
    """Basic validation of generated Manim code"""
    issues = []
    
    # Check for complete class definition
    if 'class ' not in code:
        issues.append("Missing class definition")
    if 'def construct(' not in code:
        issues.append("Missing construct method")
    
    # Check for balanced brackets
    if code.count('(') != code.count(')'):
        issues.append("Unbalanced parentheses")
    if code.count('{') != code.count('}'):
        issues.append("Unbalanced braces")
    
    # Check for image loading pattern
    if 'ImageMobject' in code and 'try:' not in code:
        issues.append("ImageMobject used without error handling")
    
    return len(issues) == 0, issues

def main():
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise ValueError("GEMINI_API_KEY environment variable not set")
    
    client = genai.Client(api_key=api_key)

    # Load content with enhanced metadata
    enhanced_metadata = load_and_process_metadata(JSON_METADATA_PATH)
    markdown = load_text(MARKDOWN_PATH)
    prompt_template = load_text(PROMPT_FILE_PATH)
    image_paths = list_image_paths(IMAGES_FOLDER)

    prompt_template_escaped = escape_braces(prompt_template)
    user_query = input("Enter what you want visualized in Manim: ").strip()

    # Enhanced prompt with image context
    full_prompt = prompt_template_escaped.format(
        query=user_query,
        document_content=markdown,
        metadata=enhanced_metadata,  # Now includes image context
        images=", ".join(image_paths),
    )

    print("Generating Manim code with image integration...")
    
    # Generate with higher token limit for image integration
    response = client.models.generate_content(
    model="gemini-2.5-flash",
    contents=full_prompt,
    config=types.GenerateContentConfig(
        temperature=0.3,
        max_output_tokens=8192,
        top_k=40,
        top_p=0.9,
        stop_sequences=["# End", "# End of Animation"],
    ),
)

# Safely extract text
    generated_code = None
    try:
        if response.text:
            generated_code = response.text
        elif response.candidates:
            # fallback extraction
            generated_code = response.candidates[0].content.parts[0].text
    except Exception as e:
        print("Error extracting generated code:", e)

    if not generated_code:
        print("‚ùå No code generated by Gemini")
        return

    # Now safe to call validation
    is_valid, issues = validate_generated_code(generated_code)

    if not is_valid:
        print(f"Code validation warnings: {', '.join(issues)}")

    # Save generated code
    with open(OUTPUT_MANIM_FILE, "w", encoding="utf-8") as f:
        f.write("# Generated by Gemini for query: " + user_query + "\n")
        f.write("# Includes automatic image integration from PDF\n")
        f.write(generated_code)

    print(f"Enhanced Manim code with images written to {OUTPUT_MANIM_FILE}")
    print(f"Images available: {len(image_paths)} files")

if __name__ == "__main__":
    main()
